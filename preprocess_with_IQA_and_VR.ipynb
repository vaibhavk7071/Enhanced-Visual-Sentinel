{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Google Colab Notebook** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">Preprocessing with IQA and VR</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mounting google drive to colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download CMake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -c \"https://github.com/Kitware/CMake/releases/download/v3.13.4/cmake-3.13.4.tar.gz\"\n",
    "! tar xf cmake-3.13.4.tar.gz\n",
    "! cd cmake-3.13.4 && ./configure && make && sudo make install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Requirements for OpenPose to work on Colab (requires 2 runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "! sudo -H pip3 install fastapi kaleido python-multipart uvicorn\n",
    "! sudo apt-get --assume-yes update\n",
    "! sudo apt-get --assume-yes install build-essential\n",
    "# OpenCV\n",
    "! sudo apt-get --assume-yes install libopencv-dev\n",
    "# General dependencies\n",
    "! sudo apt-get --assume-yes install libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler\n",
    "! sudo apt-get --assume-yes install --no-install-recommends libboost-all-dev\n",
    "# Remaining dependencies, 14.04\n",
    "! sudo apt-get --assume-yes install libgflags-dev libgoogle-glog-dev liblmdb-dev\n",
    "# Python3 libs\n",
    "! sudo apt-get --assume-yes install python3-setuptools python3-dev build-essential\n",
    "! sudo apt-get --assume-yes install python3-pip\n",
    "! sudo -H pip3 install --upgrade numpy==1.21 protobuf==3.20.3 opencv-python\n",
    "# OpenCV 2.4 -> Added as option\n",
    "# # sudo apt-get --assume-yes install libopencv-dev\n",
    "# OpenCL Generic\n",
    "! sudo apt-get --assume-yes install opencl-headers ocl-icd-opencl-dev\n",
    "! sudo apt-get --assume-yes install libviennacl-dev\n",
    "\n",
    "#  Openpose の clone\n",
    "#! git clone  --depth 1 -b \"$ver_openpose\" https://github.com/CMU-Perceptual-Computing-Lab/openpose.git\n",
    "! git clone  --depth 1 https://github.com/CMU-Perceptual-Computing-Lab/openpose.git\n",
    "\n",
    "#  Openpose の モデルデータDL\n",
    "! cd openpose/models && ./getModels.sh\n",
    "\n",
    "# Openpose の ビルド\n",
    "! sed -i 's/execute_process(COMMAND git checkout master WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/execute_process(COMMAND git checkout f019d0dfe86f49d1140961f8c7dec22130c83154 WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/g' openpose/CMakeLists.txt\n",
    "! cd openpose && rm -r build || true && mkdir build && cd build && cmake .. && make -j`nproc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Requirements for TOP-IQ (PyTorch implementation for IQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./drive/MyDrive/BTP/IQA-PyTorch && pip3 install -r requirements.txt && python3 setup.py develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Requirements for RVRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /content/drive/MyDrive/BTP/RVRT/ && pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modules for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./drive/MyDrive/BTP/IQA-PyTorch\n",
    "import glob\n",
    "import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyiqa\n",
    "import torch\n",
    "import subprocess\n",
    "import shutil\n",
    "%cd '../../../../'\n",
    "\n",
    "DATASET = 'movies'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/content'\n",
    "GAMMA = 0.67  # if GAMMA < 0, no gamma correction will be applied\n",
    "# Precompute gamma correction table\n",
    "gamma_table = np.array([((i / 255.0) ** GAMMA) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "def ProcessGammaVideo(videoName, inputPath, outputPath):\n",
    "    print(f'Generating Gamma frames for {videoName}.avi')\n",
    "    cap = cv2.VideoCapture(inputPath)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    totalFrames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(f\"{outputPath}/{videoName}.avi\", fourcc, fps, (width,  height))\n",
    "    detected = False\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            if detected:\n",
    "                print(\"Video Ended\")\n",
    "            else:\n",
    "                print(\"No Frames Detected\")\n",
    "            break\n",
    "        if not detected:\n",
    "            print(f\"Frames detected : {totalFrames}\")\n",
    "            detected = True\n",
    "        frame = cv2.LUT(frame, gamma_table)\n",
    "        out.write(frame)\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Restoration by deblurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RestoreFramesAndCreateVideo(videoName, fps, inputFrameDirectory, outputDirectory):\n",
    "    print(f\"Restoring the frames of {videoName}\")\n",
    "\n",
    "    !cd ./drive/MyDrive/BTP/RVRT && python3 main_test_rvrt.py --task 004_RVRT_videodeblurring_DVD_16frames --folder_lq /content/drive/MyDrive/BTP/Frames/VaibhavGeneratedMoviesFrames --tile 0 256 256 --tile_overlap 0 20 20 --num_workers 8 --save_video /content/drive/MyDrive/BTP/datasets/movies_dataset/VaibhavDataset/RestoredData --fps 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame Generation from clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateFrames(videoName, inputVideo, frameOutputDirectory):\n",
    "    cap = cv2.VideoCapture(inputVideo)\n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    frameOutputPath = os.path.join(frameOutputDirectory, videoName)\n",
    "    if not os.path.exists(frameOutputPath):\n",
    "        os.makedirs(frameOutputPath)\n",
    "\n",
    "    for j in range(frameCount):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, j)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        framePath = f\"{frameOutputPath}/frame_{j}.png\"\n",
    "        cv2.imwrite(framePath, frame)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IQA + VR Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QualityCheck(videoName, frameOutputDirectory, videoRestoredDirectory, fps, iqa_metric, thresholdQuality=0.6, qualityCheckFrameSize=5):\n",
    "\n",
    "    frameOutputPath = os.path.join(frameOutputDirectory, videoName)\n",
    "\n",
    "    frameScores = []\n",
    "\n",
    "    for j in range(qualityCheckFrameSize):\n",
    "        framePath = f\"{frameOutputPath}/frame_{j}.png\"\n",
    "        # Extract the score from the output\n",
    "        score = iqa_metric(f'{framePath}').item()\n",
    "        print(f\"Score for Frame : {j + 1} is {score}\")\n",
    "        frameScores.append(score)\n",
    "\n",
    "    avgScore = sum(frameScores) / len(frameScores)\n",
    "\n",
    "    if avgScore < thresholdQuality:\n",
    "        print(f\"Video {videoName} with average score {avgScore} is below the threshold quality. Processing further.\")\n",
    "        # Image restoration begins\n",
    "        RestoreFramesAndCreateVideo(videoName, fps, frameOutputDirectory, videoRestoredDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoGammaInputDirectory = f\"./drive/MyDrive/BTP/datasets/{DATASET}_dataset/VaibhavDataset/OriginalData/\"\n",
    "videoGammaOutputDirectory = f\"./drive/MyDrive/BTP/datasets/{DATASET}_dataset/VaibhavDataset/GammaData/\"\n",
    "frameOutputDirectory = f\"./drive/MyDrive/BTP/Frames/VaibhavGeneratedMoviesFrames/\"\n",
    "videoRestoredDirectory = f\"./drive/MyDrive/BTP/datasets/{DATASET}_dataset/VaibhavDataset/RestoredData/\"\n",
    "videoFinalSaveDirectory = f\"./drive/MyDrive/BTP/datasets/{DATASET}_dataset/VaibhavDataset/OpenposeData/\"\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "fps = 25\n",
    "\n",
    "# Gamma Corrected clip generation\n",
    "for file in os.listdir(videoGammaInputDirectory):\n",
    "    if file.endswith(\".avi\"):\n",
    "        inputGammaVideoPath = os.path.join(videoGammaInputDirectory, file)\n",
    "        videoName = os.path.splitext(file)[0]\n",
    "        if GAMMA > 0:\n",
    "            ProcessGammaVideo(videoName, inputGammaVideoPath, videoGammaOutputDirectory)\n",
    "\n",
    "# Splitting of clips into frames for IQA\n",
    "for file in os.listdir(videoGammaOutputDirectory):\n",
    "    if file.endswith(\".avi\"):\n",
    "        videoName = os.path.splitext(file)[0]\n",
    "        print(f'Generating frames for {videoName}')\n",
    "        videoName = os.path.splitext(file)[0]\n",
    "        inputVideo = os.path.join(videoGammaOutputDirectory, file)\n",
    "        GenerateFrames(videoName, inputVideo, frameOutputDirectory)\n",
    "        print('Frames generated')\n",
    "\n",
    "# IQA + VR\n",
    "# The quality assessed for one video is used as a parameter for the entire dataset\n",
    "iqa_metric = pyiqa.create_metric('topiq_nr', device = device)\n",
    "for file in os.listdir(frameOutputDirectory):\n",
    "    videoName = os.path.splitext(file)[0]\n",
    "    print(f'Initializing quality check for {videoName}')\n",
    "    QualityCheck(videoName, frameOutputDirectory, videoRestoredDirectory, fps, iqa_metric, 0.6, 5)\n",
    "    break\n",
    "# Add the above section to the main_test_rvrt.py file to test the scores for each video clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Openpose - Human Skeleton Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Openpose \n",
    "for file in os.listdir(videoRestoredDirectory):\n",
    "    if file.endswith(\".avi\"):\n",
    "        os.system(f'cd openpose && ./build/examples/openpose/openpose.bin --video ../{videoRestoredDirectory}{file} --display 0 --write_video ../{videoFinalSaveDirectory}{file} --disable_blending > /dev/null')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
